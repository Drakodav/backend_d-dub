{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.losses import huber_loss\n",
    "from keras import optimizers\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from bus_evaluation import evaluate\n",
    "from load_data import load_bus_trips_format2\n",
    "import threading\n",
    "\n",
    "\n",
    "def training(train_x, train_y):\n",
    "    print(\"---Training model---\")\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(None, 4)))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    # set the parameters of sgd optimizer\n",
    "    sgd = optimizers.SGD(lr=0.0001, momentum=0.95)\n",
    "    model.compile(\n",
    "        loss=huber_loss,\n",
    "        optimizer=sgd\n",
    "    )\n",
    "    # split the training set based on the length of trips\n",
    "    training_len = {}\n",
    "    max_len = 0\n",
    "    for x, y in zip(train_x, train_y):\n",
    "        x_len = len(x)\n",
    "        if x_len > max_len:\n",
    "            max_len = x_len\n",
    "        if x_len not in training_len:\n",
    "            training_len[x_len] = {\"x\": [], \"y\": []}\n",
    "        training_len[x_len][\"x\"].append(x)\n",
    "        training_len[x_len][\"y\"].append(y)\n",
    "    training_x_y = np.array(list(training_len.values()))\n",
    "    np.random.shuffle(training_x_y)\n",
    "    for value in training_x_y:\n",
    "        trip_len = len(value[\"x\"][-1])\n",
    "        # add iterations\n",
    "        epochs = 5 if trip_len > 20 else 10\n",
    "        print(\"Trip length:\", trip_len)\n",
    "        model.fit(np.array(value[\"x\"]), np.array(value[\"y\"]), epochs=epochs, batch_size=256)\n",
    "    # lower the learning rate and train again\n",
    "    sgd = optimizers.SGD(lr=0.00001, momentum=0.95)\n",
    "    model.compile(\n",
    "        loss=huber_loss,\n",
    "        optimizer=sgd\n",
    "    )\n",
    "    for value in training_x_y:\n",
    "        trip_len = len(value[\"x\"][-1])\n",
    "        print(\"Trip length:\", trip_len)\n",
    "        model.fit(np.array(value[\"x\"]), np.array(value[\"y\"]), epochs=5, batch_size=128)\n",
    "    return model\n",
    "\n",
    "\n",
    "def normalize(trips, standard_scale):\n",
    "    start_time = time.time()\n",
    "    # normalize the aggregated time\n",
    "    trips_tmp = np.array(trips).reshape((-1, trips.shape[2]))\n",
    "    agg_time = np.array(trips_tmp[..., -1]).reshape(-1, 1)\n",
    "    agg_time = np.array(standard_scale.fit_transform(agg_time)).reshape(-1, trips.shape[1])\n",
    "    trips_x = np.array([np.array([trip[..., 0][:-1], trip[..., 1][:-1], trip[..., 1][1:], agg_t[:-1]]).T\n",
    "                        for trip, agg_t in zip(trips, agg_time)])\n",
    "    # split train test based on trips, the ratio is 0.1\n",
    "    train_test_ratio = int(0.1 * len(trips_x))\n",
    "    trips_train_x, trips_test_x = trips_x[train_test_ratio:], trips_x[:train_test_ratio]\n",
    "    trips_train_y, trips_test_y = agg_time[train_test_ratio:], agg_time[:train_test_ratio]\n",
    "    train_y, test_y = np.array(trips_train_y[..., 1:]).reshape(-1), np.array(trips_test_y[..., 1:]).reshape(-1)\n",
    "    # convert to format which can be trained by lstm neural network\n",
    "    train_x, test_x = [], []\n",
    "    for trip in trips_train_x:\n",
    "        train_x.extend(np.array([trip[:i] for i in range(1, len(trip) + 1)]))\n",
    "    for trip in trips_test_x:\n",
    "        test_x.extend(np.array([np.array(trip[:i]) for i in range(1, len(trip) + 1)]))\n",
    "    print(\"Normalize target usage:\", time.time() - start_time)\n",
    "    return train_x, train_y, test_x, test_y, trips_test_y\n",
    "\n",
    "\n",
    "def rnn_predict(model, trips_test_x, trip_len):\n",
    "    # prediction begins\n",
    "    start_time = time.time()\n",
    "    predict_results = []\n",
    "    for l in range(trip_len):\n",
    "        # predict the time of position at lth\n",
    "        x = np.array([tmp[l] for tmp in trips_test_x])\n",
    "        y = model.predict(x)\n",
    "        #  use the predict result of last time predicted\n",
    "        predict_result = np.array([np.append(t[:, 3], p) for t, p in zip(x, y)])\n",
    "        for k in range(l, trip_len - 1):\n",
    "            x = np.array([np.concatenate((tmp_x[k + 1][:, :3], np.array([y]).T), axis=1) for tmp_x, y in\n",
    "                          zip(trips_test_x, predict_result)])\n",
    "            y = model.predict(x)\n",
    "            #  use the predict result of last time predicted\n",
    "            predict_result = np.array([np.append(t[:, 3], p) for t, p in zip(x, y)])\n",
    "        predict_results.append(predict_result)\n",
    "    prediction_time_used = time.time() - start_time\n",
    "    print(\"Time usage for prediction:\", prediction_time_used)\n",
    "    return predict_results, prediction_time_used\n",
    "\n",
    "\n",
    "def write_to_csv(out_dir, data):\n",
    "    with open(out_dir, \"w\", encoding='utf-8') as csv_out:\n",
    "        cw = csv.writer(csv_out)\n",
    "        cw.writerows(data)\n",
    "\n",
    "\n",
    "def rnn_evaluation(predict_results, standard_scale, trips_test_y):\n",
    "    # re-arrange the predict result\n",
    "    predict_results_trip = np.array(\n",
    "        [[result[i] for result in predict_results] for i in range(np.array(predict_results).shape[1])])\n",
    "    # add the real trip at the end of the predict result\n",
    "    predict_results = np.array(\n",
    "        [np.append(result, [test], axis=0) for result, test in zip(predict_results_trip, trips_test_y)])\n",
    "    # inverse predict result to origin scale\n",
    "    predict_results = standard_scale.inverse_transform(predict_results)\n",
    "    # only stored the integer in the prediction file\n",
    "    predict_results = np.array(np.round(predict_results), dtype=int)\n",
    "    # evaluate the result\n",
    "    MAE, MAPE, RMSE = evaluate(predict_results)\n",
    "    return MAE, MAPE, RMSE\n",
    "\n",
    "\n",
    "def run_lstm(trips):\n",
    "    # rnn_model_root_dir = home_dir + \"model_training/lstm/\" + bus_number + \"/\"\n",
    "    print(\"Test for trip length:\", trips.shape[1])\n",
    "    standard_scale = StandardScaler(with_mean=True, with_std=True)\n",
    "    # get the normalised data, trips_test_y is the target data group by trip, it is used for prediction\n",
    "    train_x, train_y, test_x, test_y, trips_test_y = normalize(trips, standard_scale)\n",
    "    start_time = time.time()\n",
    "    # model_file = rnn_model_root_dir + \"lstm{}\".format(trips.shape[1]) + \".h5\"\n",
    "    # training model\n",
    "    model = training(train_x, train_y)\n",
    "    training_time_used = time.time() - start_time\n",
    "    print(\"Time usage for training:\", training_time_used)\n",
    "    trip_len = trips.shape[1] - 1\n",
    "    # group the x by trip\n",
    "    trips_test_x = np.array(\n",
    "        [np.array(test_x[i * trip_len:(i + 1) * trip_len]) for i in range(int(len(test_x) / trip_len) - 1)])\n",
    "    # prediction begins, and get the prediction results\n",
    "    predict_results, prediction_time_used = rnn_predict(model, trips_test_x, trip_len)\n",
    "    MAE, MAPE, RMSE = rnn_evaluation(predict_results, standard_scale, trips_test_y)\n",
    "    rnn_result.append(\n",
    "        [\"LSTM RNN\", len(trips), trips.shape[1], training_time_used, prediction_time_used, MAE, MAPE, RMSE])\n",
    "    print(\"---Write data---\")\n",
    "    out_dir = result_dir + \"Result{}.csv\".format(trips.shape[1])\n",
    "    # write data format3 result file to result directory\n",
    "    write_to_csv(out_dir, rnn_result)\n",
    "    model_predict_dir = rnn_output_dir + \"{}/\".format(trips.shape[1])\n",
    "    if not os.path.exists(model_predict_dir):\n",
    "        os.mkdir(model_predict_dir)\n",
    "    # write result to a file, the final result will stored in a single file\n",
    "    for results in np.array(predict_results):\n",
    "        global trip_test\n",
    "        write_to_csv(model_predict_dir + str(trip_test) + \".csv\", results)\n",
    "        trip_test += 1\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    trips_gps = load_bus_trips_format2(home_dir, bus_number)\n",
    "    print(\"Load data usage:\", time.time() - start_time)\n",
    "    for trips in trips_gps:\n",
    "        # It may occurs some bugs when operate multi-threading process\n",
    "        # t = threading.Thread(target=run_lstm, args=(trips,))\n",
    "        # t.start()\n",
    "        run_lstm(trips)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trip_test = 0\n",
    "    # TODO change directory here\n",
    "    home_dir = \"/Users/ruixinhua/Documents/BusGPS/BusGPS/\"\n",
    "    # The prediction result is stored in the result directory\n",
    "    result_dir = home_dir + \"result/\"\n",
    "    rnn_output_dir = home_dir + \"pred_res/rnn/\"\n",
    "    bus_number = \"46\"\n",
    "    rnn_result = [[\"Model\", \"Trips Size\", \"Trips Length\", \"Training Time(s)\", \"Prediction Time(s)\", \"MAE\", \"MAPE\", \"RMSE\"]]\n",
    "    main()"
   ]
  }
 ]
}