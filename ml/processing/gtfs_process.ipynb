{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "denv",
   "display_name": "denv",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "from google.protobuf.json_format import Parse, MessageToJson\n",
    "import json\n",
    "import psycopg2\n",
    "import time\n",
    "from django.contrib.gis.geos import Point, fromstr, GEOSGeometry\n",
    "from datetime import datetime\n",
    "# from haversine import haversine, Unit\n",
    "\n",
    "dir = Path.cwd()\n",
    "outdir = os.path.join(dir, 'output')\n",
    "gtfs_records_zip = os.path.join(dir, 'data', 'GtfsRRecords.zip')\n",
    "gtfs_csv_zip = os.path.join(outdir, 'gtfsr_csv_test.zip')\n",
    "gtfs_final_csv_path = os.path.join(outdir, 'gtfsr_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query: str = ''):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"localhost\",\n",
    "            port='25432',\n",
    "            database=\"gis\",\n",
    "            user=\"docker\",\n",
    "            password=\"docker\"\n",
    "        )\n",
    "\t\t\n",
    "        # create a cursor\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "\t    # execute a statement\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "\n",
    "        colnames = [desc[0] for desc in cur.description]\n",
    "        print(colnames)\n",
    "       \n",
    "\t    # close the communication with the PostgreSQL\n",
    "        cur.close()\n",
    "        return data\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if conn is not None:\n",
    "            conn.close()\n",
    "\n",
    "# print(run_query())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['stop_id', 'point']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 stop_id        lon       lat\n",
       "0           8220DB000002  53.352244 -6.263723\n",
       "1           8220DB000003  53.352309 -6.263811\n",
       "2           8220DB000004  53.352575 -6.264175\n",
       "3           8220DB000006  53.352749 -6.264454\n",
       "4           8220DB000007  53.352841 -6.264570\n",
       "...                  ...        ...       ...\n",
       "4706        8350DB007462  53.128801 -6.062480\n",
       "4707        8350DB007522  53.188131 -6.118873\n",
       "4708        8350DB007574  53.182348 -6.130064\n",
       "4709         8350GD10395  53.192599 -6.170880\n",
       "4710  gen:57102:8223:0:1  53.471172 -6.239062\n",
       "\n",
       "[4711 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_id</th>\n      <th>lon</th>\n      <th>lat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8220DB000002</td>\n      <td>53.352244</td>\n      <td>-6.263723</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8220DB000003</td>\n      <td>53.352309</td>\n      <td>-6.263811</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8220DB000004</td>\n      <td>53.352575</td>\n      <td>-6.264175</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8220DB000006</td>\n      <td>53.352749</td>\n      <td>-6.264454</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8220DB000007</td>\n      <td>53.352841</td>\n      <td>-6.264570</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4706</th>\n      <td>8350DB007462</td>\n      <td>53.128801</td>\n      <td>-6.062480</td>\n    </tr>\n    <tr>\n      <th>4707</th>\n      <td>8350DB007522</td>\n      <td>53.188131</td>\n      <td>-6.118873</td>\n    </tr>\n    <tr>\n      <th>4708</th>\n      <td>8350DB007574</td>\n      <td>53.182348</td>\n      <td>-6.130064</td>\n    </tr>\n    <tr>\n      <th>4709</th>\n      <td>8350GD10395</td>\n      <td>53.192599</td>\n      <td>-6.170880</td>\n    </tr>\n    <tr>\n      <th>4710</th>\n      <td>gen:57102:8223:0:1</td>\n      <td>53.471172</td>\n      <td>-6.239062</td>\n    </tr>\n  </tbody>\n</table>\n<p>4711 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# get all the stop data and add the lat lon columns\n",
    "def get_stops_df(): \n",
    "    query = \"\"\"select stop_id, point from stop;\"\"\"\n",
    "    res = run_query(query)\n",
    "\n",
    "    stop_data = []\n",
    "    for s in res:\n",
    "        id, coords = s[0], GEOSGeometry(s[1]).coords\n",
    "        lon, lat = coords[1], coords[0]\n",
    "\n",
    "        stop_data.append([id, lon, lat])\n",
    "\n",
    "    return pd.DataFrame(stop_data, columns=['stop_id', 'lon', 'lat'])\n",
    "stop_df = get_stops_df()\n",
    "stop_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['id', 'point', 'sequence', 'traveled', 'trip_id', 'shape_id']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id                                              point  sequence  \\\n",
       "0    15921712  0101000020E610000084ADCD2B88F218C025EA64A4A7B1...       182   \n",
       "1    15921716  0101000020E6100000F096893242F418C0CA69A8CEA5B1...       186   \n",
       "2    15921707  0101000020E61000007FFDA2BF24F018C0CDC4A88685B1...       177   \n",
       "3    15921638  0101000020E61000001EE68D5D4ADA18C0093585BA09B1...       108   \n",
       "4    15921691  0101000020E6100000E415FEDD54E718C06BF32961C5B1...       161   \n",
       "..        ...                                                ...       ...   \n",
       "243  15921542  0101000020E61000002FDD5F39A4E518C09B90770A3FAE...        12   \n",
       "244  15921532  0101000020E6100000597EEE795FE918C0772E384868AE...         2   \n",
       "245  15921756  0101000020E610000084234E86530A19C0EF957BD20DB2...       226   \n",
       "246  15921729  0101000020E6100000E7E4DDB265FB18C0EC4CA88AB5B1...       199   \n",
       "247  15921673  0101000020E6100000637CED0B3EE618C0F4450DD9E5B1...       143   \n",
       "\n",
       "     traveled                      trip_id  shape_id  \n",
       "0     9737.18  7218.10455.2-104-gad-1.83.O     33207  \n",
       "1     9849.47  7218.10455.2-104-gad-1.83.O     33207  \n",
       "2     9537.15  7218.10455.2-104-gad-1.83.O     33207  \n",
       "3     6616.39  7218.10455.2-104-gad-1.83.O     33207  \n",
       "4     8633.66  7218.10455.2-104-gad-1.83.O     33207  \n",
       "..        ...                          ...       ...  \n",
       "243    495.60  7218.10455.2-104-gad-1.83.O     33207  \n",
       "244    100.34  7218.10455.2-104-gad-1.83.O     33207  \n",
       "245  11624.76  7218.10455.2-104-gad-1.83.O     33207  \n",
       "246  10348.15  7218.10455.2-104-gad-1.83.O     33207  \n",
       "247   8308.96  7218.10455.2-104-gad-1.83.O     33207  \n",
       "\n",
       "[248 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>point</th>\n      <th>sequence</th>\n      <th>traveled</th>\n      <th>trip_id</th>\n      <th>shape_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15921712</td>\n      <td>0101000020E610000084ADCD2B88F218C025EA64A4A7B1...</td>\n      <td>182</td>\n      <td>9737.18</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15921716</td>\n      <td>0101000020E6100000F096893242F418C0CA69A8CEA5B1...</td>\n      <td>186</td>\n      <td>9849.47</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15921707</td>\n      <td>0101000020E61000007FFDA2BF24F018C0CDC4A88685B1...</td>\n      <td>177</td>\n      <td>9537.15</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15921638</td>\n      <td>0101000020E61000001EE68D5D4ADA18C0093585BA09B1...</td>\n      <td>108</td>\n      <td>6616.39</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>15921691</td>\n      <td>0101000020E6100000E415FEDD54E718C06BF32961C5B1...</td>\n      <td>161</td>\n      <td>8633.66</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>15921542</td>\n      <td>0101000020E61000002FDD5F39A4E518C09B90770A3FAE...</td>\n      <td>12</td>\n      <td>495.60</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>15921532</td>\n      <td>0101000020E6100000597EEE795FE918C0772E384868AE...</td>\n      <td>2</td>\n      <td>100.34</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>15921756</td>\n      <td>0101000020E610000084234E86530A19C0EF957BD20DB2...</td>\n      <td>226</td>\n      <td>11624.76</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>246</th>\n      <td>15921729</td>\n      <td>0101000020E6100000E7E4DDB265FB18C0EC4CA88AB5B1...</td>\n      <td>199</td>\n      <td>10348.15</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n    <tr>\n      <th>247</th>\n      <td>15921673</td>\n      <td>0101000020E6100000637CED0B3EE618C0F4450DD9E5B1...</td>\n      <td>143</td>\n      <td>8308.96</td>\n      <td>7218.10455.2-104-gad-1.83.O</td>\n      <td>33207</td>\n    </tr>\n  </tbody>\n</table>\n<p>248 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# get all the stop data and add the lat lon columns\n",
    "def get_shape_points_df(trip_id= '7218.10455.2-104-gad-1.83.O'): \n",
    "    query = \"\"\"\n",
    "    select shape_point.id, shape_point.point, shape_point.sequence, shape_point.traveled,\n",
    "        trip.trip_id, trip.shape_id\n",
    "    from shape_point \n",
    "    join shape on shape.id = shape_point.shape_id\n",
    "    join trip on shape.id = trip.shape_id\n",
    "    where \n",
    "        trip.trip_id = '{}'\n",
    "    group by trip.id, shape_point.id\n",
    "    ;\n",
    "    \"\"\".format(trip_id).lstrip()\n",
    "    res = run_query(query)\n",
    "\n",
    "    # shape_data = []\n",
    "    # for s in res:\n",
    "    #     id, coords = s[0], GEOSGeometry(s[1]).coords\n",
    "    #     lon, lat = coords[1], coords[0]\n",
    "\n",
    "    #     shape_data.append([id, lon, lat])\n",
    "\n",
    "    df = pd.DataFrame(res, columns=['id', 'point', 'sequence', 'traveled', 'trip_id', 'shape_id'])\n",
    "    # df = df.merge(pd.DataFrame(shape_data, columns=['id', 'lat', 'lon']), on=['id'])\n",
    "    # df['point'] = df['point'].apply(lambda p: GEOSGeometry(p))\n",
    "    return df\n",
    "\n",
    "shape_p_df = get_shape_points_df()\n",
    "shape_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      [-0.10885352515582798, 0.9317951337178745]\n",
       "1      [-0.10888295483722178, 0.9317941563869947]\n",
       "2      [-0.10881281723878293, 0.9317769623560963]\n",
       "3      [-0.10844034865162448, 0.9317110238629611]\n",
       "4      [-0.10866262284807732, 0.9318109728053591]\n",
       "                          ...                    \n",
       "243    [-0.10863381789537548, 0.9313303581637725]\n",
       "244    [-0.10869741765605748, 0.9313523245664395]\n",
       "245     [-0.1092590815480145, 0.9318495580957188]\n",
       "246    [-0.10900462809517107, 0.9318025370211336]\n",
       "247    [-0.10864405924602917, 0.9318282664746157]\n",
       "Name: point, Length: 248, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "shape_p_df['point'].apply(lambda p: np.radians(GEOSGeometry(p).coords))\n",
    "# haversine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure',\n",
      "       'arrival', 'lon', 'lat'],\n",
      "      dtype='object')\n",
      "Index(['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure',\n",
      "       'arrival', 'lon', 'lat'],\n",
      "      dtype='object')\n",
      "finished processing\n"
     ]
    }
   ],
   "source": [
    "# here we split the data into smaller chunks by getting rid\n",
    "# of what we dont need\n",
    "def process_gtfsr():\n",
    "    __file__ = Path().cwd()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    gtfsRecords = os.path.join(__file__, 'GtfsRRecords.zip')\n",
    "\n",
    "    query = \"\"\"select trip_id from trip;\"\"\"\n",
    "    trip_id_list = [id[0].replace('-d12-', '-b12-', 1)\n",
    "                    for id in run_query(query)]\n",
    "\n",
    "    # write to a new records file which we can then use to process data faster\n",
    "    with zipfile.ZipFile(os.path.join(__file__, 'gtfsr_csv.zip'), 'w') as zf:\n",
    "\n",
    "        # read from the gtfs records\n",
    "        with zipfile.ZipFile(gtfsRecords, 'r') as zip:\n",
    "            dirs = zip.namelist()\n",
    "            dirs_len = len(dirs)\n",
    "\n",
    "            for i in range(15, 17):\n",
    "                feed = gtfs_realtime_pb2.FeedMessage()\n",
    "                entity_data = []\n",
    "\n",
    "                try:\n",
    "                    realtime_data = zip.read(dirs[i])\n",
    "                    Parse(realtime_data, feed)\n",
    "                except:\n",
    "                    print('{}.json is a bad file, continue'.format(i))\n",
    "                    continue\n",
    "\n",
    "                for entity in feed.entity:\n",
    "                    if entity.HasField('trip_update'):\n",
    "                        trip_id = entity.trip_update.trip.trip_id\n",
    "\n",
    "                        if trip_id in trip_id_list:\n",
    "                            trip = entity.trip_update.trip\n",
    "                            stop_time_update = entity.trip_update.stop_time_update\n",
    "\n",
    "                            for s in stop_time_update: \n",
    "                                arr = s.arrival.delay if s.HasField('arrival') else 0\n",
    "                                entity_data.append([trip.trip_id, trip.start_date, trip.start_time, s.stop_sequence, s.departure.delay, s.stop_id, arr])\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    print('{}/{}'.format(i, dirs_len),\n",
    "                        'time: {}s'.format(round(time.time() - start)))\n",
    "\n",
    "                if len(entity_data) > 0:\n",
    "                    # create the entity\n",
    "                    entity_df = pd.DataFrame(entity_data, columns=['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'stop_id', 'arrival'])\n",
    "                    df = pd.merge(entity_df, stop_df, on=['stop_id'])\n",
    "                    del df['stop_id']\n",
    "\n",
    "                    # return MessageToJson(feed)\n",
    "                    zf.writestr(\"{}.csv\".format(i), df.to_csv(header=False, index=False),\n",
    "                                compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "    print('finished processing')\n",
    "    return\n",
    "process_gtfsr()\n",
    "# data = process_gtfsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            trip_id start_date start_time  stop_sequence  \\\n",
       "0        1149518.7.10-32-e19-1.93.O   20210109   14:45:00              1   \n",
       "1        1149518.7.10-32-e19-1.93.O   20210109   14:45:00              2   \n",
       "2        1149518.7.10-32-e19-1.93.O   20210109   14:45:00              3   \n",
       "3        1149518.7.10-32-e19-1.93.O   20210109   14:45:00              4   \n",
       "4        1149518.7.10-32-e19-1.93.O   20210109   14:45:00              5   \n",
       "...                             ...        ...        ...            ...   \n",
       "1564  1154197.7.10-301-e19-1.1156.O   20210109   19:55:00              1   \n",
       "1565  11496.10846.2-331-ga2-1.260.I   20210109   19:55:00              1   \n",
       "1566  11496.10846.2-331-ga2-1.260.I   20210109   19:55:00             62   \n",
       "1567  12828.10846.2-451-ga2-1.308.O   20210109   19:55:00              1   \n",
       "1568   8562.10846.2-114-ga2-1.107.I   20210109   19:55:00              1   \n",
       "\n",
       "      departure       stop_id  arrival  \n",
       "0             0  8220B1350002        0  \n",
       "1          7380   8240B111931     7260  \n",
       "2          7620  8300B1524301     7560  \n",
       "3          7260  8540B6012201     7260  \n",
       "4          7140  8540B1559301     7140  \n",
       "...         ...           ...      ...  \n",
       "1564          0  8400B6090201        0  \n",
       "1565          0  8240DB003815        0  \n",
       "1566          0  8240DB007348        0  \n",
       "1567          0  8350DB004533        0  \n",
       "1568          0  8250DB003085        0  \n",
       "\n",
       "[1569 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>start_date</th>\n      <th>start_time</th>\n      <th>stop_sequence</th>\n      <th>departure</th>\n      <th>stop_id</th>\n      <th>arrival</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1149518.7.10-32-e19-1.93.O</td>\n      <td>20210109</td>\n      <td>14:45:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8220B1350002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1149518.7.10-32-e19-1.93.O</td>\n      <td>20210109</td>\n      <td>14:45:00</td>\n      <td>2</td>\n      <td>7380</td>\n      <td>8240B111931</td>\n      <td>7260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1149518.7.10-32-e19-1.93.O</td>\n      <td>20210109</td>\n      <td>14:45:00</td>\n      <td>3</td>\n      <td>7620</td>\n      <td>8300B1524301</td>\n      <td>7560</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1149518.7.10-32-e19-1.93.O</td>\n      <td>20210109</td>\n      <td>14:45:00</td>\n      <td>4</td>\n      <td>7260</td>\n      <td>8540B6012201</td>\n      <td>7260</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1149518.7.10-32-e19-1.93.O</td>\n      <td>20210109</td>\n      <td>14:45:00</td>\n      <td>5</td>\n      <td>7140</td>\n      <td>8540B1559301</td>\n      <td>7140</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1564</th>\n      <td>1154197.7.10-301-e19-1.1156.O</td>\n      <td>20210109</td>\n      <td>19:55:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8400B6090201</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1565</th>\n      <td>11496.10846.2-331-ga2-1.260.I</td>\n      <td>20210109</td>\n      <td>19:55:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8240DB003815</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1566</th>\n      <td>11496.10846.2-331-ga2-1.260.I</td>\n      <td>20210109</td>\n      <td>19:55:00</td>\n      <td>62</td>\n      <td>0</td>\n      <td>8240DB007348</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1567</th>\n      <td>12828.10846.2-451-ga2-1.308.O</td>\n      <td>20210109</td>\n      <td>19:55:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8350DB004533</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1568</th>\n      <td>8562.10846.2-114-ga2-1.107.I</td>\n      <td>20210109</td>\n      <td>19:55:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8250DB003085</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1569 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "## flatten trip and stop entity data\n",
    "\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "Parse(data, feed)\n",
    "entity_data = []\n",
    "\n",
    "for entity in feed.entity: \n",
    "    trip = entity.trip_update.trip\n",
    "    stop_time_update = entity.trip_update.stop_time_update\n",
    "\n",
    "    for s in stop_time_update: \n",
    "        arr = s.arrival.delay if s.HasField('arrival') else 0\n",
    "        entity_data.append([trip.trip_id, trip.start_date, trip.start_time, s.stop_sequence, s.departure.delay, s.stop_id, arr])\n",
    "\n",
    "entity_df = pd.DataFrame(entity_data, columns=['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'stop_id', 'arrival'])\n",
    "entity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      trip_id start_date start_time  stop_sequence  departure  \\\n",
       "0    11777.2.60-13-b12-1.22.I   20210109   18:00:00              1          0   \n",
       "1    11756.2.60-13-b12-1.22.I   20210109   18:15:00              1          0   \n",
       "2    11370.2.60-13-b12-1.23.I   20210109   19:00:00              1          0   \n",
       "3    11379.2.60-13-b12-1.19.O   20210109   18:00:00              1          0   \n",
       "4    11394.2.60-13-b12-1.19.O   20210109   18:15:00              1          0   \n",
       "..                        ...        ...        ...            ...        ...   \n",
       "104  8299.2.60-120-b12-1.59.O   20210109   19:15:00              1          0   \n",
       "105  7510.2.60-130-b12-1.73.O   20210109   19:20:00              1          0   \n",
       "106  7485.2.60-130-b12-1.74.I   20210109   19:20:00              1          0   \n",
       "107  10746.2.60-47-b12-1.43.O   20210109   19:30:00              1          0   \n",
       "108  9599.2.60-56A-b12-1.53.O   20210109   19:45:00              1          0   \n",
       "\n",
       "     schedule       lon       lat  \n",
       "0           0  0.930786 -0.112593  \n",
       "1           0  0.930786 -0.112593  \n",
       "2           0  0.930786 -0.112593  \n",
       "3           0  0.932315 -0.109583  \n",
       "4           0  0.932315 -0.109583  \n",
       "..        ...       ...       ...  \n",
       "104         0  0.931184 -0.109267  \n",
       "105         0  0.931114 -0.109202  \n",
       "106         0  0.931395 -0.108298  \n",
       "107         0  0.931078 -0.109162  \n",
       "108         0  0.930992 -0.108826  \n",
       "\n",
       "[109 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>start_date</th>\n      <th>start_time</th>\n      <th>stop_sequence</th>\n      <th>departure</th>\n      <th>schedule</th>\n      <th>lon</th>\n      <th>lat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11777.2.60-13-b12-1.22.I</td>\n      <td>20210109</td>\n      <td>18:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.930786</td>\n      <td>-0.112593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>11756.2.60-13-b12-1.22.I</td>\n      <td>20210109</td>\n      <td>18:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.930786</td>\n      <td>-0.112593</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11370.2.60-13-b12-1.23.I</td>\n      <td>20210109</td>\n      <td>19:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.930786</td>\n      <td>-0.112593</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11379.2.60-13-b12-1.19.O</td>\n      <td>20210109</td>\n      <td>18:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.932315</td>\n      <td>-0.109583</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11394.2.60-13-b12-1.19.O</td>\n      <td>20210109</td>\n      <td>18:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.932315</td>\n      <td>-0.109583</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>8299.2.60-120-b12-1.59.O</td>\n      <td>20210109</td>\n      <td>19:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.931184</td>\n      <td>-0.109267</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>7510.2.60-130-b12-1.73.O</td>\n      <td>20210109</td>\n      <td>19:20:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.931114</td>\n      <td>-0.109202</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>7485.2.60-130-b12-1.74.I</td>\n      <td>20210109</td>\n      <td>19:20:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.931395</td>\n      <td>-0.108298</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>10746.2.60-47-b12-1.43.O</td>\n      <td>20210109</td>\n      <td>19:30:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.931078</td>\n      <td>-0.109162</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>9599.2.60-56A-b12-1.53.O</td>\n      <td>20210109</td>\n      <td>19:45:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.930992</td>\n      <td>-0.108826</td>\n    </tr>\n  </tbody>\n</table>\n<p>109 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "df = pd.merge(entity_df, stop_df, on=['stop_id'])\n",
    "del df['stop_id']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished cobining the zip files, time: 0\n"
     ]
    }
   ],
   "source": [
    "def combine_csv():\n",
    "    __file__ = Path().cwd()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    gtfs_csv_zip = os.path.join(__file__, 'gtfsr_csv.zip')\n",
    "    columns = ['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'arrival', 'lon', 'lat']\n",
    "\n",
    "    # read from the gtfs records\n",
    "    with zipfile.ZipFile(gtfs_csv_zip, 'r') as zip:\n",
    "        dirs = zip.namelist()\n",
    "        dirs_len = len(dirs)\n",
    "\n",
    "        combined_csv = pd.concat([pd.read_csv(zip.open(f),header=None) for f in dirs])\n",
    "        combined_csv.columns = columns\n",
    "        combined_csv.to_csv('gtfsr_combined_csv.csv', index=False, header=True)\n",
    "  \n",
    "    print('finished cobining the zip files, time: {}'.format(round(time.time() - start)))\n",
    "    return\n",
    "combine_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['id', 'point', 'sequence', 'traveled', 'extra_data', 'shape_id']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(15920413,\n",
       "  '0101000020E61000004301C8D260F718C0DAC62F98C0B64A40',\n",
       "  1,\n",
       "  0.0,\n",
       "  '{}',\n",
       "  33204)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "run_query('select * from shape_point limit 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# lets return a iterable that can be chunked\n",
    "def chunked_iterable(iterable, size):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, size))\n",
    "        if not chunk:\n",
    "            break\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['stop_id', 'point']\n",
      "['trip_id']\n",
      "0/30152 time: 0s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " '5020.1.60-40-d12-1.202.O',\n",
       " '6299.1.60-13-d12-1.18.O',\n",
       " '6305.1.60-13-d12-1.18.O',\n",
       " '1452.1.60-27-d12-1.149.O',\n",
       " '1460.1.60-27-d12-1.149.O',\n",
       " '6364.1.60-13-d12-1.18.O',\n",
       " '11777.2.60-13-b12-1.22.I',\n",
       " '11777.2.60-13-b12-1.22.I',\n",
       " '11777.2.60-13-b12-1.22.I',\n",
       " '11777.2.60-13-b12-1.22.I']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from joblib import delayed, Parallel, dump\n",
    "import re\n",
    "\n",
    "def find_trip_regex(trip_list, trip_id):\n",
    "    assert type(trip_id) == str, 'trip_id must be string'\n",
    "\n",
    "    tokens = trip_id.split('.')\n",
    "    if not len(tokens) == 5:\n",
    "        return None\n",
    "\n",
    "    route_id = tokens[2].split('-')\n",
    "    if route_id[2] in ['ga2', 'gad']:\n",
    "        route_id[2] = 'ga[2|d]'\n",
    "        tokens[2] = '-'.join(route_id)\n",
    "    elif route_id[2] in ['d12', 'b12']: \n",
    "        route_id[2] = '[b|d]12'\n",
    "        tokens[2] = '-'.join(route_id)\n",
    "\n",
    "    tokens[3] = '*'\n",
    "\n",
    "    reg = '.'.join(tokens)\n",
    "\n",
    "    r = re.compile(reg)\n",
    "    matched_list = list(filter(r.match, trip_list))\n",
    "\n",
    "    if len(matched_list) > 0:\n",
    "        return matched_list[0]\n",
    "    else: return None\n",
    "\n",
    "# splits from the main processing in order to allow multiple threads and cores\n",
    "# for performance reasons\n",
    "def multi_compute(i, data, trip_id_list, stop_df):\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    entity_data = []\n",
    "\n",
    "    try:\n",
    "        Parse(data, feed)\n",
    "    except:\n",
    "        print('{}.json is a bad file, continue'.format(i))\n",
    "        return\n",
    "\n",
    "    # get feed timestamp and iterate through all the entities\n",
    "    timestamp = datetime.fromtimestamp(feed.header.timestamp)\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('trip_update'):\n",
    "            trip_id = find_trip_regex(trip_id_list, entity.trip_update.trip.trip_id)\n",
    "\n",
    "            # if the trip id exists in our database when can then continue processing\n",
    "            if not trip_id == None:\n",
    "                trip = entity.trip_update.trip\n",
    "                stop_time_update = entity.trip_update.stop_time_update\n",
    "\n",
    "                # for every stop_time_update we append add the fields needed\n",
    "                for s in stop_time_update:\n",
    "                    arr = s.arrival.delay if s.HasField(\n",
    "                        'arrival') else 0\n",
    "                    entity_data.append(\n",
    "                        [trip_id, trip.start_date, trip.start_time, s.stop_sequence, int(s.departure.delay), arr, timestamp, s.stop_id])\n",
    "\n",
    "    # only if we have an existing trip in the feed we can produce a csv file\n",
    "    if len(entity_data) > 0:\n",
    "        # create the entity\n",
    "        entity_df = pd.DataFrame(entity_data, columns=[\n",
    "            'trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'arrival', 'timestamp', 'stop_id'])\n",
    "\n",
    "        # merge the entity stop_id data with the stop lat lon from database\n",
    "        df = pd.merge(entity_df, stop_df, on=['stop_id'])\n",
    "        # print(df)\n",
    "\n",
    "        return df.to_csv(header=False, index=False)\n",
    "\n",
    "\n",
    "# here we split the data into smaller chunks by getting rid\n",
    "# of what we dont need, this is done by only including the trips where\n",
    "# we have a match in our database and disregarding the rest\n",
    "def process_gtfsr_to_csv(chunk_size=1000):\n",
    "    start = time.time()\n",
    "    stop_df = get_stops_df()\n",
    "\n",
    "    query = \"\"\"select trip_id from trip;\"\"\"\n",
    "    trip_id_list = [id[0] for id in run_query(query)]\n",
    "\n",
    "    # write to a new records file which we can then use to process data faster\n",
    "    # with zipfile.ZipFile(gtfs_csv_zip, 'w') as zf:\n",
    "\n",
    "    # read from the gtfs records\n",
    "    with zipfile.ZipFile(gtfs_records_zip, 'r') as zip:\n",
    "        dirs = zip.namelist()\n",
    "        dirs_len = len(dirs)\n",
    "\n",
    "        curr_i = 0\n",
    "        for c in chunked_iterable(dirs, size=chunk_size):\n",
    "            # friendly printing to update user\n",
    "            print('{}/{}'.format(curr_i, dirs_len),\n",
    "                    'time: {}s'.format(round(time.time() - start)))\n",
    "\n",
    "            # [multi_compute(curr_i+i, zip.read(dir), trip_id_list, stop_df) for i, dir in enumerate(c)]\n",
    "\n",
    "            delayed_func = [delayed(multi_compute)(curr_i+i, zip.read(dir), trip_id_list, stop_df)\n",
    "                            for i, dir in enumerate(c)]\n",
    "            parallel_pool = Parallel(n_jobs=8)\n",
    "\n",
    "            res = parallel_pool(delayed_func)\n",
    "            return res\n",
    "\n",
    "            # # write csv to zip\n",
    "            # for i, r in enumerate(res):\n",
    "            #     if not r == None:\n",
    "            #         zf.writestr(\"{}.csv\".format(curr_i+i), r,\n",
    "            #                     compress_type=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "            # curr_i += chunk_size\n",
    "\n",
    "    print('finished processing')\n",
    "    return\n",
    "gtfsr = process_gtfsr_to_csv(19)\n",
    "gtfsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       trip_id  start_date start_time  stop_sequence  \\\n",
       "0     5033.1.60-40-b12-1.206.O    20210111   12:00:00              1   \n",
       "1     5044.1.60-40-b12-1.206.O    20210111   12:12:00              1   \n",
       "2       5722.1.60-9-b12-1.10.O    20210111   12:12:00              1   \n",
       "3       5796.1.60-9-b12-1.10.O    20210111   12:24:00              1   \n",
       "4     5113.1.60-40-b12-1.206.O    20210111   12:24:00              1   \n",
       "..                         ...         ...        ...            ...   \n",
       "187  10798.2.60-42-b12-1.239.I    20210109   19:15:00              1   \n",
       "188   8299.2.60-120-b12-1.59.O    20210109   19:15:00              1   \n",
       "189   6799.2.60-54A-b12-1.51.I    20210109   19:15:00              1   \n",
       "190   7485.2.60-130-b12-1.74.I    20210109   19:20:00              1   \n",
       "191   7510.2.60-130-b12-1.73.O    20210109   19:20:00              1   \n",
       "\n",
       "     departure  arrival            timestamp       stop_id        lon  \\\n",
       "0            0        0  2021-01-11 13:26:43  8240DB007132  53.403089   \n",
       "1            0        0  2021-01-11 13:26:43  8240DB007132  53.403089   \n",
       "2            0        0  2021-01-11 13:26:43  8240DB007132  53.403089   \n",
       "3            0        0  2021-01-11 13:26:43  8240DB007132  53.403089   \n",
       "4            0        0  2021-01-11 13:26:43  8240DB007132  53.403089   \n",
       "..         ...      ...                  ...           ...        ...   \n",
       "187          0        0  2021-01-09 19:31:08  8240DB003605  53.433968   \n",
       "188          0        0  2021-01-09 19:31:08  8220DB006004  53.352908   \n",
       "189          0        0  2021-01-09 19:31:08  8230DB005161  53.270891   \n",
       "190          0        0  2021-01-09 19:31:08  8220DB001772  53.365011   \n",
       "191          0        0  2021-01-09 19:31:08  8220DB007591  53.348890   \n",
       "\n",
       "          lat  \n",
       "0   -6.304307  \n",
       "1   -6.304307  \n",
       "2   -6.304307  \n",
       "3   -6.304307  \n",
       "4   -6.304307  \n",
       "..        ...  \n",
       "187 -6.124919  \n",
       "188 -6.260512  \n",
       "189 -6.371901  \n",
       "190 -6.205021  \n",
       "191 -6.256830  \n",
       "\n",
       "[2726 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>start_date</th>\n      <th>start_time</th>\n      <th>stop_sequence</th>\n      <th>departure</th>\n      <th>arrival</th>\n      <th>timestamp</th>\n      <th>stop_id</th>\n      <th>lon</th>\n      <th>lat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5033.1.60-40-b12-1.206.O</td>\n      <td>20210111</td>\n      <td>12:00:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-11 13:26:43</td>\n      <td>8240DB007132</td>\n      <td>53.403089</td>\n      <td>-6.304307</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5044.1.60-40-b12-1.206.O</td>\n      <td>20210111</td>\n      <td>12:12:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-11 13:26:43</td>\n      <td>8240DB007132</td>\n      <td>53.403089</td>\n      <td>-6.304307</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5722.1.60-9-b12-1.10.O</td>\n      <td>20210111</td>\n      <td>12:12:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-11 13:26:43</td>\n      <td>8240DB007132</td>\n      <td>53.403089</td>\n      <td>-6.304307</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5796.1.60-9-b12-1.10.O</td>\n      <td>20210111</td>\n      <td>12:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-11 13:26:43</td>\n      <td>8240DB007132</td>\n      <td>53.403089</td>\n      <td>-6.304307</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5113.1.60-40-b12-1.206.O</td>\n      <td>20210111</td>\n      <td>12:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-11 13:26:43</td>\n      <td>8240DB007132</td>\n      <td>53.403089</td>\n      <td>-6.304307</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>10798.2.60-42-b12-1.239.I</td>\n      <td>20210109</td>\n      <td>19:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8240DB003605</td>\n      <td>53.433968</td>\n      <td>-6.124919</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>8299.2.60-120-b12-1.59.O</td>\n      <td>20210109</td>\n      <td>19:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8220DB006004</td>\n      <td>53.352908</td>\n      <td>-6.260512</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>6799.2.60-54A-b12-1.51.I</td>\n      <td>20210109</td>\n      <td>19:15:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8230DB005161</td>\n      <td>53.270891</td>\n      <td>-6.371901</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>7485.2.60-130-b12-1.74.I</td>\n      <td>20210109</td>\n      <td>19:20:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8220DB001772</td>\n      <td>53.365011</td>\n      <td>-6.205021</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>7510.2.60-130-b12-1.73.O</td>\n      <td>20210109</td>\n      <td>19:20:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8220DB007591</td>\n      <td>53.348890</td>\n      <td>-6.256830</td>\n    </tr>\n  </tbody>\n</table>\n<p>2726 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "from io import StringIO\n",
    "\n",
    "columns = ['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'arrival', 'timestamp', 'stop_id', 'lon', 'lat']\n",
    "\n",
    "gtfsr_df = pd.DataFrame()\n",
    "gtfsr_df = gtfsr_df.fillna(0)\n",
    "for r in gtfsr: \n",
    "    if not r == None:\n",
    "        temp_df = pd.read_csv(StringIO(r))\n",
    "        temp_df.columns = columns\n",
    "        gtfsr_df = pd.concat([gtfsr_df, temp_df])\n",
    "gtfsr_df.columns = columns\n",
    "gtfsr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     trip_id  start_date start_time  stop_sequence  departure  \\\n",
       "51  8803.2.60-16-b12-1.129.I    20210109   18:24:00             73          0   \n",
       "52  8813.2.60-16-b12-1.128.O    20210109   18:24:00              1          0   \n",
       "95  8803.2.60-16-b12-1.129.I    20210109   18:24:00              1          0   \n",
       "40  8803.2.60-16-b12-1.129.I    20210109   18:24:00             73          0   \n",
       "41  8813.2.60-16-b12-1.128.O    20210109   18:24:00              1          0   \n",
       "85  8803.2.60-16-b12-1.129.I    20210109   18:24:00              1          0   \n",
       "40  8813.2.60-16-b12-1.128.O    20210109   18:24:00              1          0   \n",
       "41  8803.2.60-16-b12-1.129.I    20210109   18:24:00             73          0   \n",
       "80  8803.2.60-16-b12-1.129.I    20210109   18:24:00              1          0   \n",
       "27  8803.2.60-16-b12-1.129.I    20210109   18:24:00             73          0   \n",
       "28  8813.2.60-16-b12-1.128.O    20210109   18:24:00              1          0   \n",
       "61  8803.2.60-16-b12-1.129.I    20210109   18:24:00              1          0   \n",
       "\n",
       "    arrival            timestamp       stop_id        lon       lat  \n",
       "51        0  2021-01-09 19:28:02  8240DB007347  53.428020 -6.242021  \n",
       "52        0  2021-01-09 19:28:02  8240DB007347  53.428020 -6.242021  \n",
       "95        0  2021-01-09 19:28:02  8250DB005171  53.271736 -6.248261  \n",
       "40        0  2021-01-09 19:28:54  8240DB007347  53.428020 -6.242021  \n",
       "41        0  2021-01-09 19:28:54  8240DB007347  53.428020 -6.242021  \n",
       "85        0  2021-01-09 19:28:54  8250DB005171  53.271736 -6.248261  \n",
       "40        0  2021-01-09 19:30:02  8240DB007347  53.428020 -6.242021  \n",
       "41        0  2021-01-09 19:30:02  8240DB007347  53.428020 -6.242021  \n",
       "80        0  2021-01-09 19:30:02  8250DB005171  53.271736 -6.248261  \n",
       "27        0  2021-01-09 19:31:08  8240DB007347  53.428020 -6.242021  \n",
       "28        0  2021-01-09 19:31:08  8240DB007347  53.428020 -6.242021  \n",
       "61        0  2021-01-09 19:31:08  8250DB005171  53.271736 -6.248261  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trip_id</th>\n      <th>start_date</th>\n      <th>start_time</th>\n      <th>stop_sequence</th>\n      <th>departure</th>\n      <th>arrival</th>\n      <th>timestamp</th>\n      <th>stop_id</th>\n      <th>lon</th>\n      <th>lat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>51</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:02</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>8813.2.60-16-b12-1.128.O</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:02</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:02</td>\n      <td>8250DB005171</td>\n      <td>53.271736</td>\n      <td>-6.248261</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:54</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>8813.2.60-16-b12-1.128.O</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:54</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:28:54</td>\n      <td>8250DB005171</td>\n      <td>53.271736</td>\n      <td>-6.248261</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>8813.2.60-16-b12-1.128.O</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:30:02</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:30:02</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:30:02</td>\n      <td>8250DB005171</td>\n      <td>53.271736</td>\n      <td>-6.248261</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>73</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>8813.2.60-16-b12-1.128.O</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8240DB007347</td>\n      <td>53.428020</td>\n      <td>-6.242021</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>8803.2.60-16-b12-1.129.I</td>\n      <td>20210109</td>\n      <td>18:24:00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2021-01-09 19:31:08</td>\n      <td>8250DB005171</td>\n      <td>53.271736</td>\n      <td>-6.248261</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# gtfsr_df.drop_duplicates(subset=['trip_id', 'start_date', 'start_time', 'stop_sequence', 'departure', 'arrival'], keep='last')\n",
    "gtfsr_df[gtfsr_df['start_time'] == '18:24:00']"
   ]
  }
 ]
}